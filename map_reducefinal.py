# -*- coding: utf-8 -*-
"""map_reducefinal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ag6VtbmfVMlNxElbVv95juxHbYKMGKB4

Map reduce

program 1:Word Count using Python
"""

from google.colab import files
uploaded = files.upload()

from collections import defaultdict
def read_text_file(filename):
 with open(filename,'r') as file:
  return file.read()
def mapper(text):
 word_counts = []
 for line in text.strip().split("\n"):
  for word in line.strip().split():
   word_counts.append((word.lower(), 1))
 return word_counts

def reducer(mapped_data):
 reduced_counts = defaultdict(int)
 for word, count in mapped_data:
  reduced_counts[word] += count
 return reduced_counts
text = read_text_file("example1.txt")
mapped = mapper(text)
reduced = reducer(mapped)
for word, count in reduced.items():
 print(f"{word}: {count}")

"""program 2:Analyze Student Marks using Python"""

from google.colab import files
uploaded = files.upload()

from collections import defaultdict

def mapper(lines):
 mapped_data = []
 for line in lines:

  student, subject, mark = line.strip().split(",")
  mapped_data.append((student, int(mark)))
 return mapped_data

def shuffle(mapped_data):
 grouped = defaultdict(list)
 for student, mark in mapped_data:
  grouped[student].append(mark)
 return grouped

def reducer(grouped_data):
 reduced = {}
 for student, marks in grouped_data.items():
  avg = sum(marks) / len(marks)
  high = max(marks)
  low = min(marks)
  reduced[student] = {
  "Average": avg,
  "Highest": high,
  "Lowest": low
}
 return reduced

def output_results(results):
 print("Student Performance Summary:")
 for student, stats in results.items():
  print(f"{student}: Avg={stats['Average']:.2f}, High={stats['Highest']},Low={stats['Lowest']}")
 print("\n Students with Average > 80:")
 for student, stats in results.items():
  if stats['Average'] > 80:
   print(f"{student}: Avg={stats['Average']:.2f}")

if __name__ == "__main__":
 filename = next(iter(uploaded)) # Assuming &#39;uploaded&#39; contains the filename
 with open(filename, 'r') as file:
  lines = file.readlines()

mapped = mapper(lines)
grouped = shuffle(mapped)
reduced = reducer(grouped)
output_results(reduced)

"""Program 3: Filtering Out Common Words using Python"""

from google.colab import files
uploaded = files.upload()

import string
from collections import defaultdict
# Mapper
def mapper(paragraph, stop_words):
 # Create a translation table to remove punctuation
 translator = str.maketrans('', '', string.punctuation)
 clean_text = paragraph.translate(translator).lower()
 words = clean_text.strip().split()
 mapped = []

 for word in words:
  if word and word not in stop_words: # Added check for empty string after removing punctuation
   mapped.append((word, word))
 return mapped

# Shuffle &amp; Sort
def shuffle(mapped_data):
 grouped = defaultdict(list)
 for key, value in mapped_data:
  grouped[key].append(value)
 return grouped
# Reducer

def reducer(grouped_data):
 filtered_words = []
 for word, group in grouped_data.items():
  filtered_words.extend(group)
 return ' '.join(filtered_words)

# Runner
if __name__ == "__main__":
 stop_words = {"is","the","a","an","and"}
 file_name = list(uploaded.keys())[0]
 with open(file_name,'r') as f:
  paragraph = f.read()
 mapped = mapper(paragraph, stop_words)
 grouped = shuffle(mapped)
 filtered_paragraph = reducer(grouped)
 print(filtered_paragraph)

